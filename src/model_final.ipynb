{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cc4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from probability_estimator import ProbabilityEstimator\n",
    "from environment import Environment\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "import sklearn\n",
    "import sklearn.compose\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from lukas import DataExtraction # Start writing code here...\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae8111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "generator = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09fac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/training_data.csv', parse_dates=['Date', 'Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f03361",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(dataset[(dataset.H == False) & (dataset.A == False)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6ebed303",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "name 'd' is used prior to global declaration (3799772255.py, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_19112/3799772255.py\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    teamh = dataset2.loc[(dataset2[\"HID\"] == team)]\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m name 'd' is used prior to global declaration\n"
     ]
    }
   ],
   "source": [
    "class ModelWrapper:\n",
    "    def __init__(self):\n",
    "        self.team_stats = {}\n",
    "        for i in range(30): self.team_stats[i] = {\"wins\": 0, \"shots\": 0, \"won_buly\": 0, \"penalty\": 0, \"matches\": 0, \"odds\": 0}\n",
    "        self.model = sklearn.linear_model.LogisticRegression(max_iter=800, random_state=42)\n",
    "        # self.bookmaker_h = sklearn.linear_model.LinearRegression()\n",
    "        # self.bookmaker_a = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "        self.poly = sklearn.preprocessing.PolynomialFeatures(2)\n",
    "        self.scaler = sklearn.preprocessing.StandardScaler(with_mean=False)\n",
    "        \n",
    "        self.data = np.empty(shape=(0, 18))\n",
    "        self.home_wins = np.empty(shape=(0,1))\n",
    "        self.oddsh = np.empty(shape=(0,1))\n",
    "        self.oddsa = np.empty(shape=(0,1))\n",
    "        self.reset_factor = 1.4\n",
    "\n",
    "    def reset_stats(self, team_id):\n",
    "        self.team_stats[team_id][\"wins\"] /= self.reset_factor\n",
    "        self.team_stats[team_id][\"shots\"] /= self.reset_factor\n",
    "        self.team_stats[team_id][\"penalty\"] /= self.reset_factor\n",
    "        self.team_stats[team_id][\"matches\"] //= self.reset_factor\n",
    "        self.team_stats[team_id][\"odds\"] //= self.reset_factor\n",
    "        \n",
    "    def add_stats(self, team_id, match, is_home):\n",
    "        home = [\"S_H\", \"FOW_H\", \"PIM_H\", \"OddsH\"]\n",
    "        away = [\"S_A\", \"FOW_A\", \"PIM_A\", \"OddsA\"]\n",
    "        if is_home: keys = home\n",
    "        else: keys = away\n",
    "        self.team_stats[team_id][\"shots\"] += match[keys[0]]\n",
    "        self.team_stats[team_id][\"won_buly\"] += match[keys[1]]\n",
    "        self.team_stats[team_id][\"penalty\"] += match[keys[2]]\n",
    "        self.team_stats[team_id][\"odds\"] += match[keys[3]]\n",
    "        self.team_stats[team_id][\"matches\"] += 1\n",
    "\n",
    "    def process_new_matches(self, inc):\n",
    "        attributes = (\"S\", \"PIM\", \"PPG\", \"FOW\")\n",
    "        teams = set()\n",
    "        for i, r in enumerate(dataset.iterrows()):\n",
    "            match = r[1]\n",
    "            teams.add(match[\"HID\"])\n",
    "            teams.add(match[\"AID\"])\n",
    "        d = {}\n",
    "        for team in teams:\n",
    "            teamh = dataset.loc[(dataset[\"HID\"] == team)]\n",
    "            teama = dataset.loc[(dataset[\"AID\"] == team)]\n",
    "            tot = len(teamh) + len(teama)\n",
    "            for a in attributes:\n",
    "                if not team in d:\n",
    "                    d[team] = {}\n",
    "                val = (np.sum(teamh[a + \"_H\"]) + np.sum(teamh[a + \"_A\"])) / tot\n",
    "                d[team][a] = val\n",
    "            val = (np.sum(teamh[\"HSC\"]) + np.sum(teamh[\"ASC\"])) / tot\n",
    "            d[team][\"SC\"] = val\n",
    "        for i, r in enumerate(inc.iterrows()):\n",
    "            if i % 500 == 0:\n",
    "                if i > 500:\n",
    "                    dataset2 = inc.tail(500)\n",
    "                else:\n",
    "                    dataset2 = inc\n",
    "                attributes = (\"S\", \"PIM\", \"PPG\", \"FOW\")\n",
    "                global d\n",
    "                d = {}\n",
    "                for team in teams:\n",
    "                    teamh = dataset2.loc[(dataset2[\"HID\"] == team)]\n",
    "                    teama = dataset2.loc[(dataset2[\"AID\"] == team)]\n",
    "                    tot = len(teamh) + len(teama)\n",
    "                    for a in attributes:\n",
    "                        if not team in d:\n",
    "                            d[team] = {}\n",
    "                        val = (np.sum(teamh[a + \"_H\"]) + np.sum(teamh[a + \"_A\"])) / tot\n",
    "                        d[team][a] = val\n",
    "                    val = (np.sum(teamh[\"HSC\"]) + np.sum(teamh[\"ASC\"])) / tot\n",
    "                    d[team][\"SC\"] = val\n",
    "            match = r[1]\n",
    "            th, ta = match[\"HID\"], match[\"AID\"] \n",
    "\n",
    "            # ignore games with draw\n",
    "            if (match[\"H\"] or match[\"A\"]):\n",
    "                # +1 to avoid div zero error\n",
    "                mh, ma = self.team_stats[th][\"matches\"] + 1, self.team_stats[ta][\"matches\"] + 1\n",
    "                new_row = np.array([\n",
    "                    [self.team_stats[th][\"wins\"]/mh, \n",
    "                     self.team_stats[th][\"shots\"]/mh, \n",
    "                    self.team_stats[th][\"won_buly\"]/mh, \n",
    "                     self.team_stats[th][\"odds\"]/mh,\n",
    "                    self.team_stats[ta][\"wins\"]/ma, \n",
    "                     self.team_stats[ta][\"shots\"]/ma, \n",
    "                    self.team_stats[ta][\"won_buly\"]/ma, \n",
    "                     self.team_stats[ta][\"odds\"]/ma,\n",
    "                     d[th][\"S\"],\n",
    "                     d[ta][\"S\"],\n",
    "                     d[th][\"PIM\"],\n",
    "                    d[ta][\"PIM\"],\n",
    "                    d[th][\"PPG\"],\n",
    "                    d[ta][\"PPG\"],\n",
    "                    d[th][\"FOW\"],\n",
    "                    d[ta][\"FOW\"],\n",
    "                    d[th][\"SC\"],\n",
    "                    d[ta][\"SC\"],\n",
    "                    ]\n",
    "                ])\n",
    "                #print(self.team_stats[ta][\"wins\"]/ma)\n",
    "                #print(match[\"H\"])\n",
    "                self.data = np.append(self.data, new_row, axis=0)\n",
    "                \n",
    "                if match[\"H\"]: self.home_wins = np.append(self.home_wins, 0)\n",
    "                else: self.home_wins = np.append(self.home_wins, 1)\n",
    "                    \n",
    "                        \n",
    "            # lower the importance of old matches\n",
    "            if self.team_stats[th][\"matches\"] % 30==0: self.reset_stats(th)\n",
    "            if self.team_stats[ta][\"matches\"] % 30==0: self.reset_stats(ta)\n",
    "                \n",
    "            if match[\"H\"]: self.team_stats[th][\"wins\"] += 1 \n",
    "            self.add_stats(th, match, True)\n",
    "            \n",
    "            if match[\"A\"]: self.team_stats[ta][\"wins\"] += 1 \n",
    "            self.add_stats(ta, match, False)\n",
    "\n",
    "                    \n",
    "    def predict(self, th, ta):\n",
    "        mh, ma = self.team_stats[th][\"matches\"], self.team_stats[ta][\"matches\"]\n",
    "        inp = self.poly.transform([[\n",
    "                self.team_stats[th][\"wins\"]/mh, self.team_stats[th][\"shots\"]/mh, \n",
    "                self.team_stats[th][\"won_buly\"]/mh, self.team_stats[th][\"odds\"]/mh,\n",
    "                self.team_stats[th][\"wins\"]/ma, self.team_stats[th][\"shots\"]/ma, \n",
    "                self.team_stats[th][\"won_buly\"]/ma, self.team_stats[th][\"odds\"]/ma,\n",
    "        ]])\n",
    "        \n",
    "        inp = self.scaler.transform(inp)\n",
    "        return self.model.predict_proba(inp)\n",
    "\n",
    "    def fit(self):\n",
    "        inp = self.poly.fit_transform(self.data)\n",
    "        inp = self.scaler.fit_transform(inp)\n",
    "        self.model.fit(inp, self.home_wins)\n",
    "\n",
    "    def place_bets(self, opps, summary, inc):\n",
    "        self.process_new_matches(inc)\n",
    "        self.fit( 0)\n",
    "        \n",
    "        N = len(opps)\n",
    "        min_bet = summary.iloc[0].to_dict()['Min_bet']\n",
    "        bets = np.zeros((N, 2))\n",
    "        \n",
    "        for idx, row in enumerate(opps.iterrows()):\n",
    "            match = row[1]\n",
    "            match_date = match[\"Date\"]\n",
    "            \n",
    "            team_a, team_b = match[\"HID\"], match[\"AID\"]\n",
    "            prediciton = self.predict(team_a, team_b)[0]\n",
    "\n",
    "            if prediciton[0] >= 0.8: bets[idx, 0] = min_bet*(1+prediciton[0])\n",
    "            elif prediciton[1] >= 0.8: bets[idx, 1] = min_bet*(1+prediciton[1])\n",
    "        return pd.DataFrame(data=bets, columns=['BetH', 'BetA'], index=opps.index)\n",
    "\n",
    "    def evaluate(self):\n",
    "        model = [\n",
    "                    \n",
    "            (\"scaler\", sklearn.preprocessing.RobustScaler()),\n",
    "                 (\"poly\", sklearn.preprocessing.PolynomialFeatures(2)),\n",
    "                  (\"lr\", sklearn.linear_model.LogisticRegression(max_iter=1000)),\n",
    "#                 (\"xgb\",  xgb.XGBClassifier(objective=\"binary:logistic\", \n",
    "#                                            colsample_bytree=0.5,\n",
    "#                                            gamma=0.2,\n",
    "#                                            learnin_rate=0.01,\n",
    "#                                            max_depth=2,\n",
    "#                                            reg_lambda=0.1,\n",
    "#                                            scale_pos_weight=0.5,\n",
    "#                                            subsample=0.8\n",
    "#                                           )),\n",
    "\n",
    "                ]\n",
    "        pipeline = sklearn.pipeline.Pipeline(model)\n",
    "        print(self.data.shape)\n",
    "        results = sklearn.model_selection.cross_validate(pipeline, self.data, self.home_wins, cv=5)\n",
    "        return np.average(results['test_score'])\n",
    "    \n",
    "    def manual_evaluate(self):\n",
    "        train_data, test_data, train_target, test_target= sklearn.model_selection.train_test_split(self.data, \n",
    "                                                            self.home_wins, test_size=0.2, random_state=42)\n",
    "        model = [(\"scaler\", sklearn.preprocessing.RobustScaler()),\n",
    "                 (\"poly\", sklearn.preprocessing.PolynomialFeatures(2)),\n",
    "                  (\"lr\", sklearn.linear_model.LogisticRegression(max_iter=1500)),\n",
    "#                   (\"xgb\",  xgb.XGBClassifier(objective=\"binary:logistic\", \n",
    "#                                            colsample_bytree=0.5,\n",
    "#                                            gamma=0.2,\n",
    "#                                            learnin_rate=0.01,\n",
    "#                                            max_depth=2,\n",
    "#                                            reg_lambda=0.1,\n",
    "#                                            scale_pos_weight=0.5,\n",
    "#                                            subsample=0.8\n",
    "#                                           )\n",
    "#                   )\n",
    "                ]\n",
    "        pipeline = sklearn.pipeline.Pipeline(model)\n",
    "        pipeline.fit(train_data, train_target)\n",
    "        print(self.data)\n",
    "        return pipeline.score(test_data, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "24997edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgb__colsample_bytree': 0.5,\n",
       " 'xgb__gamma': 0.2,\n",
       " 'xgb__learning_rate': 0.01,\n",
       " 'xgb__max_depth': 2,\n",
       " 'xgb__reg_lambda': 0.1,\n",
       " 'xgb__scale_pos_weight': 0.5,\n",
       " 'xgb__subsample': 0.8}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'xgb__colsample_bytree': 0.5,\n",
    " 'xgb__gamma': 0.2,\n",
    " 'xgb__learning_rate': 0.01,\n",
    " 'xgb__max_depth': 2,\n",
    " 'xgb__reg_lambda': 0.1,\n",
    " 'xgb__scale_pos_weight': 0.5,\n",
    " 'xgb__subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fde2cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper()\n",
    "model.process_new_matches(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c9d4cb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5336, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arklez/miniconda3/envs/hackathon/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/arklez/miniconda3/envs/hackathon/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/arklez/miniconda3/envs/hackathon/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/arklez/miniconda3/envs/hackathon/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/arklez/miniconda3/envs/hackathon/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5755295922271482"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6eb09c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.93939696e-01 2.73644582e+01 5.15391304e+02 ... 2.79891293e+01\n",
      "  4.38153846e+02 1.67461538e+00]\n",
      " [2.81168188e-01 3.04949306e+01 4.04178571e+02 ... 2.90430306e+01\n",
      "  5.07043478e+02 2.49478261e+00]\n",
      " [6.00783843e-01 3.06590743e+01 3.99714286e+02 ... 3.55383778e+01\n",
      "  4.87760000e+02 1.49040000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.manual_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7461a661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.home_wins[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7cc23623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.10000000e+01, 3.90000000e+01, ...,\n",
       "        2.80000000e+01, 3.50000000e+01, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.30000000e+01, 3.40000000e+01, ...,\n",
       "        2.90000000e+01, 2.70000000e+01, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.00000000e+01, 3.50000000e+01, ...,\n",
       "        2.10000000e+01, 3.60000000e+01, 0.00000000e+00],\n",
       "       ...,\n",
       "       [2.16784841e+00, 8.98245516e+01, 1.18850000e+04, ...,\n",
       "        1.00014269e+02, 1.14180000e+04, 5.60000000e+00],\n",
       "       [1.87297434e+00, 1.35645308e+02, 1.13430000e+04, ...,\n",
       "        1.13784331e+02, 1.16870000e+04, 7.25000000e+00],\n",
       "       [3.14279059e+00, 1.09410967e+02, 1.12220000e+04, ...,\n",
       "        1.19192252e+02, 1.22200000e+04, 3.73000000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b88f0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2334.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model.home_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a94aa76b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,  21.        ,  39.        ,   0.        ,\n",
       "          1.        ,  28.        ,  35.        ,   0.        ],\n",
       "       [  1.        ,  33.        ,  34.        ,   0.        ,\n",
       "          0.        ,  29.        ,  27.        ,   0.        ],\n",
       "       [  1.        ,  30.        ,  35.        ,   0.        ,\n",
       "          0.        ,  21.        ,  36.        ,   0.        ],\n",
       "       [  0.        ,  24.        ,  37.        ,   0.        ,\n",
       "          1.        ,  41.71428571,  57.        ,   0.        ],\n",
       "       [  1.        ,  20.        ,  24.        ,   0.        ,\n",
       "          0.        ,  33.        ,  40.        ,   0.        ],\n",
       "       [  0.        ,  26.        ,   0.        ,   0.        ,\n",
       "          1.        ,  33.        ,   0.        ,   0.        ],\n",
       "       [  1.        ,  34.        ,  34.        ,   0.        ,\n",
       "          0.        ,  30.        ,  34.        ,   0.        ],\n",
       "       [  1.        ,  29.        ,  42.        ,   0.        ,\n",
       "          0.71428571,  54.        ,  74.        ,   0.        ],\n",
       "       [  0.        ,  20.        ,  40.        ,   0.        ,\n",
       "          1.        ,  31.        ,  31.        ,   0.        ],\n",
       "       [  0.        ,  19.        ,  38.        ,   0.        ,\n",
       "          1.        ,  52.57142857,  72.        ,   0.        ],\n",
       "       [  1.        ,  39.        ,  39.        ,   0.        ,\n",
       "          0.        ,  36.        ,  35.        ,   0.        ],\n",
       "       [  1.71428571,  41.28571429,  62.        ,   0.        ,\n",
       "          0.        ,  47.71428571,  69.        ,   0.        ],\n",
       "       [  0.71428571,  55.57142857,  68.        ,   0.        ,\n",
       "          1.        ,  25.        ,  26.        ,   0.        ],\n",
       "       [  0.        ,  21.        ,  32.        ,   0.        ,\n",
       "          1.        ,  40.        ,  67.        ,   0.        ],\n",
       "       [  1.        ,  18.        ,  31.        ,   0.        ,\n",
       "          0.        ,  47.42857143,  59.        ,   0.        ],\n",
       "       [  0.        ,  28.        ,  27.        ,   0.        ,\n",
       "          1.        ,  28.        ,  30.        ,   0.        ],\n",
       "       [  0.71428571,  45.57142857,   0.        ,   0.        ,\n",
       "          1.        ,  59.57142857,   0.        ,   0.        ],\n",
       "       [  1.71428571,  45.42857143,  75.        ,   0.        ,\n",
       "          0.71428571,  44.14285714,  72.        ,   0.        ],\n",
       "       [  1.        ,  20.        ,  32.        ,   0.        ,\n",
       "          0.        ,  24.        ,  34.        ,   0.        ],\n",
       "       [  0.71428571,  52.85714286,  72.        ,   0.        ,\n",
       "          1.71428571,  77.55102041, 112.        ,   0.        ],\n",
       "       [  0.        ,  16.        ,  41.        ,   0.        ,\n",
       "          1.71428571,  70.79591837,  87.        ,   0.        ],\n",
       "       [  1.71428571,  39.85714286,  50.        ,   0.        ,\n",
       "          0.        ,  48.14285714,  70.        ,   0.        ],\n",
       "       [  0.        ,  43.        ,  73.        ,   0.        ,\n",
       "          1.51020408,  70.53061224, 104.        ,   0.        ],\n",
       "       [  0.71428571,  43.85714286,  54.        ,   0.        ,\n",
       "          1.        ,  40.14285714,  73.        ,   0.        ],\n",
       "       [  0.        ,  45.        ,  71.        ,   0.        ,\n",
       "          1.        ,  19.        ,  36.        ,   0.        ],\n",
       "       [  1.        ,  22.        ,  26.        ,   0.        ,\n",
       "          0.71428571,  49.67346939, 102.        ,   0.        ],\n",
       "       [  1.51020408,  64.32653061,  91.        ,   0.        ,\n",
       "          0.        ,  20.        ,  37.        ,   0.        ],\n",
       "       [  1.71428571,  52.        ,  71.        ,   0.        ,\n",
       "          0.        ,  62.87755102,  82.        ,   0.        ],\n",
       "       [  0.51020408,  67.75510204, 103.        ,   0.        ,\n",
       "          2.2244898 ,  56.46938776,  99.        ,   0.        ],\n",
       "       [  0.51020408,  74.57142857, 111.        ,   0.        ,\n",
       "          1.71428571,  45.71428571,  69.        ,   0.        ],\n",
       "       [  1.51020408,  57.48104956, 140.        ,   0.        ,\n",
       "          0.51020408,  66.69387755, 101.        ,   0.        ],\n",
       "       [  0.        ,  53.14285714, 112.        ,   0.        ,\n",
       "          1.        ,  57.71428571, 106.        ,   0.        ],\n",
       "       [  1.2244898 ,  71.56851312, 114.        ,   0.        ,\n",
       "          1.71428571,  36.57142857,  76.        ,   0.        ],\n",
       "       [  0.71428571,  51.57142857,  98.        ,   0.        ,\n",
       "          1.36443149,  72.26530612, 149.        ,   0.        ],\n",
       "       [  1.        ,  29.57142857,  69.        ,   0.        ,\n",
       "          1.2244898 ,  55.48979592,  99.        ,   0.        ],\n",
       "       [  1.71428571,  68.55102041,  30.        ,   0.        ,\n",
       "          0.        ,  36.42857143,  78.        ,   0.        ],\n",
       "       [  2.0787172 ,  77.37900875, 157.        ,   0.        ,\n",
       "          1.58892128,  58.33527697, 117.        ,   0.        ],\n",
       "       [  1.71428571,  39.28571429,  61.        ,   0.        ,\n",
       "          0.71428571,  55.28571429,  65.        ,   0.        ],\n",
       "       [  2.2244898 ,  69.65306122,  98.        ,   0.        ,\n",
       "          1.2244898 ,  57.44897959, 114.        ,   0.        ],\n",
       "       [  1.51020408,  60.55102041,  22.        ,   0.        ,\n",
       "          0.        ,  44.28571429,  80.        ,   0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2857d219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear): Linear(in_features=45, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear = nn.Linear(45, 1)\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "mlp = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "49a6c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target= sklearn.model_selection.train_test_split(model.data, \n",
    "                                                            model.home_wins, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "19b5a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [(\"scaler\", sklearn.preprocessing.RobustScaler()),\n",
    "                 (\"poly\", sklearn.preprocessing.PolynomialFeatures(2)),\n",
    "                ]\n",
    "pipeline = sklearn.pipeline.Pipeline(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a100fa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pipeline.fit_transform(train_data)\n",
    "test_data = pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "532146ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4268, 45)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabba2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
